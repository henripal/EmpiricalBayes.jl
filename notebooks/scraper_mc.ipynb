{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "from string import ascii_lowercase\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LETTERS = '#' + ascii_lowercase\n",
    "BASE_URL = 'http://www.metacritic.com/browse/movies/title/dvd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup_from_url(url, attempt=0):\n",
    "    attempt = attempt + 1\n",
    "    time.sleep(int(random.random()*20))\n",
    "    if attempt > 10:\n",
    "        return None\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={'User-Agent': 'chrome'})\n",
    "        html = urllib.request.urlopen(req).read()\n",
    "        return BeautifulSoup(html, \"lxml\")\n",
    "    except:\n",
    "        make_soup_from_url(url, attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_soup(letter, page, attempt = 0):\n",
    "    if letter == '#':\n",
    "        url = BASE_URL + \"?page=\" + str(page)\n",
    "    else:\n",
    "        url = BASE_URL + \"/\" + letter + \"?page=\" + str(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing letter: # ...\n",
      "processing letter: a ...\n",
      "processing letter: b ...\n",
      "processing letter: c ...\n",
      "processing letter: d ...\n",
      "processing letter: e ...\n",
      "processing letter: f ...\n",
      "processing letter: g ...\n",
      "processing letter: h ...\n",
      "processing letter: i ...\n",
      "processing letter: j ...\n",
      "processing letter: k ...\n",
      "processing letter: l ...\n",
      "processing letter: m ...\n",
      "processing letter: n ...\n",
      "processing letter: o ...\n",
      "processing letter: p ...\n",
      "processing letter: q ...\n",
      "processing letter: r ...\n",
      "processing letter: s ...\n",
      "processing letter: t ...\n",
      "processing letter: u ...\n",
      "processing letter: v ...\n",
      "processing letter: w ...\n",
      "processing letter: x ...\n",
      "processing letter: y ...\n",
      "processing letter: z ...\n"
     ]
    }
   ],
   "source": [
    "for letter in LETTERS:\n",
    "    print('processing letter: ' + letter + ' ...')\n",
    "    page = 0\n",
    "    while True:\n",
    "        soup = make_soup(letter, page)\n",
    "        \n",
    "        if soup:\n",
    "            results = soup.find_all('tr', {'class': 'summary_row'})\n",
    "            links = [result.find('td', {'class': 'title_wrapper'}).find('a')['href'] for result in results]\n",
    "        else:\n",
    "            links = []\n",
    "        \n",
    "        movie_list = movie_list + links\n",
    "        \n",
    "        if links:\n",
    "            page = page + 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/movielist_mc', 'wb') as f:\n",
    "    pickle.dump(movie_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping individual pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append('../src/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "INDIV_URL = 'http://www.metacritic.com'\n",
    "TR_FIELDS = ['runtime', 'movie_rating', 'company'] \n",
    "MULTI_TR_FIELDS = ['languages', 'countries', 'genres']\n",
    "import csv\n",
    "import Movies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/movielist_mc', 'rb') as f:\n",
    "    movie_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# oh, lisp, where art thou\n",
    "def get_name(v):\n",
    "    return [ k for k,v in locals().iteritems() if v is blah][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_write(name, index):\n",
    "    with open('../data/' + name + str(index) + '.csv', 'w') as f:\n",
    "        csv_writer = csv.writer(f)\n",
    "        csv_writer.writerows(eval(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_read(name, index):\n",
    "    result = []\n",
    "    with open('../data/' + name + str(index) + '.csv', 'r') as f:\n",
    "        csv_reader = csv.reader(f)\n",
    "        for row in csv_reader:\n",
    "            result.append(row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def my_append(url_id, array, iterable):\n",
    "    try:\n",
    "        if isinstance(iterable, str):\n",
    "            array.append([url_id, iterable])\n",
    "        else:\n",
    "            for item in iterable:\n",
    "                array.append([url_id, item])\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "Finished 2581 out of 8445\n",
      "Finished 2601 out of 8445\n",
      "Finished 2621 out of 8445\n",
      "Finished 2641 out of 8445\n",
      "Finished 2661 out of 8445\n",
      "Finished 2681 out of 8445\n",
      "Finished 2701 out of 8445\n",
      "Finished 2721 out of 8445\n",
      "Finished 2741 out of 8445\n",
      "Finished 2761 out of 8445\n",
      "Finished 2781 out of 8445\n",
      "Finished 2801 out of 8445\n",
      "Finished 2821 out of 8445\n",
      "Finished 2841 out of 8445\n",
      "Finished 2861 out of 8445\n",
      "Finished 2881 out of 8445\n",
      "Finished 2901 out of 8445\n",
      "Finished 2921 out of 8445\n",
      "Finished 2941 out of 8445\n",
      "Finished 2961 out of 8445\n",
      "Finished 2981 out of 8445\n",
      "Finished 3001 out of 8445\n",
      "Finished 3021 out of 8445\n",
      "Finished 3041 out of 8445\n",
      "Finished 3061 out of 8445\n",
      "Finished 3081 out of 8445\n",
      "Finished 3101 out of 8445\n",
      "Finished 3121 out of 8445\n",
      "Finished 3141 out of 8445\n",
      "Finished 3161 out of 8445\n",
      "Finished 3181 out of 8445\n",
      "Finished 3201 out of 8445\n",
      "Finished 3221 out of 8445\n",
      "Finished 3241 out of 8445\n",
      "Finished 3261 out of 8445\n",
      "Finished 3281 out of 8445\n",
      "Finished 3301 out of 8445\n",
      "Finished 3321 out of 8445\n",
      "Finished 3341 out of 8445\n",
      "Finished 3361 out of 8445\n"
     ]
    }
   ],
   "source": [
    "basics =[]\n",
    "languages = []\n",
    "countries =[]\n",
    "genres = []\n",
    "cast = []\n",
    "director = []\n",
    "producer =[]\n",
    "writer = []\n",
    "reviews = []\n",
    "\n",
    "table_list = ['basics', 'languages', 'countries', 'genres', 'cast', 'director', 'producer', 'writer', 'reviews']\n",
    "\n",
    "print('starting...')\n",
    "start_at = 3361\n",
    "\n",
    "for index, movie in enumerate(movie_list):\n",
    "    if index < start_at:\n",
    "        # don't do anything\n",
    "        continue\n",
    "    elif index == start_at:\n",
    "        # load csvs\n",
    "        for name in table_list:\n",
    "            exec(name + '= my_read(\\'' + name + '\\', 1001)')\n",
    "        continue\n",
    "    \n",
    "    if index%20 == 1:\n",
    "        print('Finished ' + str(index) + ' out of ' + str(len(movie_list)))\n",
    "        for name in table_list:\n",
    "            my_write(name, 1001)\n",
    "        \n",
    "        \n",
    "            \n",
    "    url_id = movie[7:] \n",
    "    scraped = Movies.Movie(url_id)\n",
    "    basics.append([url_id, \n",
    "             scraped.title, scraped.metascore, scraped.user_score,\n",
    "             scraped.release_date, scraped.runtime, scraped.movie_rating,\n",
    "             scraped.company, scraped.user_reviews[0], scraped.user_reviews[1],\n",
    "            scraped.user_reviews[2]])\n",
    "    \n",
    "    my_append(url_id, languages, scraped.languages)\n",
    "    my_append(url_id, countries, scraped.countries)\n",
    "    my_append(url_id, genres, scraped.genres)\n",
    "    my_append(url_id, cast, scraped.cast)\n",
    "    my_append(url_id, director, scraped.director)\n",
    "    my_append(url_id, producer, scraped.producer)\n",
    "    my_append(url_id, writer, scraped.writer)\n",
    "    \n",
    "    reviews = reviews + [list((url_id,) + review) for review in scraped.reviews]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3361"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scraped.users_soup.find(\"Positive:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', 'English'], ['999', 'English'], ['pent', 'English']]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', 'USA'], ['999', 'Israel'], ['999', 'Australia'], ['pent', 'USA']]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', '70', 'Village Voice', 'Rob Staeger'],\n",
       " ['horror', '65', 'TheWrap', 'Inkoo Kang'],\n",
       " ['horror', '60', 'Los Angeles Times', 'Mark Olsen'],\n",
       " ['horror', '50', 'Slant Magazine', 'Chuck Bowen'],\n",
       " ['horror', '40', 'The New York Times', 'Jeannette Catsoulis'],\n",
       " ['horror', '30', 'The Hollywood Reporter', 'Frank Scheck'],\n",
       " ['horror', '12', 'RogerEbert.com', 'Peter Sobczynski'],\n",
       " ['999', '91', 'Entertainment Weekly', 'Lisa Schwarzbaum'],\n",
       " ['999', '91', 'Christian Science Monitor', 'Peter Rainer'],\n",
       " ['999', '88', 'Philadelphia Inquirer', 'Steven Rea'],\n",
       " ['999', '75', 'The A.V. Club', 'Tasha Robinson'],\n",
       " ['999', '75', 'New York Post', 'Kyle Smith'],\n",
       " ['999', '75', 'Boston Globe', 'Janice Page'],\n",
       " ['999', '75', 'San Francisco Chronicle', 'Peter Hartlaub'],\n",
       " ['999', '75', 'St. Louis Post-Dispatch', 'Calvin Wilson'],\n",
       " ['999', '70', 'L.A. Weekly', 'Ella Taylor'],\n",
       " ['999', '70', 'The Hollywood Reporter', 'Kirk Honeycutt'],\n",
       " ['999', '70', 'The New York Times', 'A.O. Scott'],\n",
       " ['999', '70', 'Washington Post', \"Michael O'Sullivan\"],\n",
       " ['999', '50', 'Los Angeles Times', 'Sheri Linden'],\n",
       " ['999', '50', 'Variety', 'Eddie Cockrell'],\n",
       " ['999', '40', 'New York Daily News', 'Joe Neumaier'],\n",
       " ['pent', '70', 'Film.com', 'Ernest Hardy'],\n",
       " ['pent', '60', 'Los Angeles Times', 'Kevin Thomas'],\n",
       " ['pent', '60', 'Variety', 'David Sprague'],\n",
       " ['pent', '40', 'TV Guide Magazine', 'Maitland McDonagh'],\n",
       " ['pent', '30', 'Village Voice', 'Mark Holcomb'],\n",
       " ['pent', '30', 'The New York Times', 'A.O. Scott'],\n",
       " ['pent', '30', 'L.A. Weekly', 'Paul Malcolm'],\n",
       " ['pent', '25', 'New York Post', 'Jonathan Foreman']]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Movies' from '../src/Movies.py'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andy Wachowski', 'Lana Wachowski']"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ha.director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horror'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_list[0][7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
