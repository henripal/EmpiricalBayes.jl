{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "from string import ascii_lowercase\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LETTERS = '#' + ascii_lowercase\n",
    "BASE_URL = 'http://www.metacritic.com/browse/movies/title/dvd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_soup_from_url(url, attempt=0):\n",
    "    attempt = attempt + 1\n",
    "    time.sleep(int(random.random()*20))\n",
    "    if attempt > 10:\n",
    "        return None\n",
    "    try:\n",
    "        req = urllib.request.Request(url, headers={'User-Agent': 'chrome'})\n",
    "        html = urllib.request.urlopen(req).read()\n",
    "        return BeautifulSoup(html, \"lxml\")\n",
    "    except:\n",
    "        make_soup_from_url(url, attempt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_soup(letter, page, attempt = 0):\n",
    "    if letter == '#':\n",
    "        url = BASE_URL + \"?page=\" + str(page)\n",
    "    else:\n",
    "        url = BASE_URL + \"/\" + letter + \"?page=\" + str(page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "movie_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing letter: # ...\n",
      "processing letter: a ...\n",
      "processing letter: b ...\n",
      "processing letter: c ...\n",
      "processing letter: d ...\n",
      "processing letter: e ...\n",
      "processing letter: f ...\n",
      "processing letter: g ...\n",
      "processing letter: h ...\n",
      "processing letter: i ...\n",
      "processing letter: j ...\n",
      "processing letter: k ...\n",
      "processing letter: l ...\n",
      "processing letter: m ...\n",
      "processing letter: n ...\n",
      "processing letter: o ...\n",
      "processing letter: p ...\n",
      "processing letter: q ...\n",
      "processing letter: r ...\n",
      "processing letter: s ...\n",
      "processing letter: t ...\n",
      "processing letter: u ...\n",
      "processing letter: v ...\n",
      "processing letter: w ...\n",
      "processing letter: x ...\n",
      "processing letter: y ...\n",
      "processing letter: z ...\n"
     ]
    }
   ],
   "source": [
    "for letter in LETTERS:\n",
    "    print('processing letter: ' + letter + ' ...')\n",
    "    page = 0\n",
    "    while True:\n",
    "        soup = make_soup(letter, page)\n",
    "        \n",
    "        if soup:\n",
    "            results = soup.find_all('tr', {'class': 'summary_row'})\n",
    "            links = [result.find('td', {'class': 'title_wrapper'}).find('a')['href'] for result in results]\n",
    "        else:\n",
    "            links = []\n",
    "        \n",
    "        movie_list = movie_list + links\n",
    "        \n",
    "        if links:\n",
    "            page = page + 1\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/movielist_mc', 'wb') as f:\n",
    "    pickle.dump(movie_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping individual pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INDIV_URL = 'http://www.metacritic.com'\n",
    "TR_FIELDS = ['runtime', 'movie_rating', 'company'] \n",
    "MULTI_TR_FIELDS = ['languages', 'countries', 'genres']\n",
    "import csv\n",
    "import Movies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/movielist_mc', 'rb') as f:\n",
    "    movie_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_append(url_id, array, iterable):\n",
    "    try:\n",
    "        if isinstance(iterable, str):\n",
    "            array.append([url_id, iterable])\n",
    "        else:\n",
    "            for item in iterable:\n",
    "                array.append([url_id, item])\n",
    "    excetp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "languages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_append(url_id, languages, scraped.languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', 'English'],\n",
       " ['999', 'English'],\n",
       " ['999', 'English'],\n",
       " ['999', 'English'],\n",
       " ['999', 'English']]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting...\n",
      "Finished 0 out of 8445\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-447-2c09e287dfee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mmy_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscraped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mmy_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproducer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscraped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproducer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mmy_append\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscraped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreviews\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscraped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-423-6d33914dd2c9>\u001b[0m in \u001b[0;36mmy_append\u001b[0;34m(url_id, array, iterable)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0murl_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0murl_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "basics =[]\n",
    "languages = []\n",
    "countries =[]\n",
    "genres = []\n",
    "cast = []\n",
    "director = []\n",
    "producer =[]\n",
    "writer = []\n",
    "reviews = []\n",
    "print('starting...')\n",
    "for index, movie in enumerate(movie_list):\n",
    "    if index%100 == 1:\n",
    "        print('Finished ' + str(index) + ' out of ' + str(len(movie_list)))\n",
    "        \n",
    "    if index%1000 == 1:\n",
    "        with open(\"../data/basics\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(basics)\n",
    "        with open(\"../data/languages\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(languages)\n",
    "        with open(\"../data/countries\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(countries)\n",
    "        with open(\"../data/genres\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(genres)\n",
    "        with open(\"../data/cast\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(cast)\n",
    "        with open(\"../data/director\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(director)\n",
    "        with open(\"../data/producer\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(producer)\n",
    "        with open(\"../data/writer\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(writer)\n",
    "        with open(\"../data/reviews\" +str(index)+\".csv\", \"w\") as f:\n",
    "            csv_writer = csv.writer(f)\n",
    "            csv_writer.writerows(reviews)\n",
    "            \n",
    "    url_id = movie[7:] \n",
    "    scraped = Movies.Movie(url_id)\n",
    "    basics.append([url_id, \n",
    "             scraped.title, scraped.metascore, scraped.user_score,\n",
    "             scraped.release_date, scraped.runtime, scraped.movie_rating,\n",
    "             scraped.company, scraped.user_reviews[0], scraped.user_reviews[1],\n",
    "            scraped.user_reviews[2]])\n",
    "    \n",
    "    my_append(url_id, languages, scraped.languages)\n",
    "    my_append(url_id, countries, scraped.countries)\n",
    "    my_append(url_id, genres, scraped.genres)\n",
    "    my_append(url_id, cast, scraped.cast)\n",
    "    my_append(url_id, director, scraped.director)\n",
    "    my_append(url_id, producer, scraped.producer)\n",
    "    my_append(url_id, writer, scraped.writer)\n",
    "    \n",
    "    reviews = reviews + [list((url_id,) + review) for review in scraped.reviews]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so-goes-the-nation'"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped.url_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', 'English'], ['999', 'English'], ['pent', 'English']]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', 'USA'], ['999', 'Israel'], ['999', 'Australia'], ['pent', 'USA']]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['horror', '70', 'Village Voice', 'Rob Staeger'],\n",
       " ['horror', '65', 'TheWrap', 'Inkoo Kang'],\n",
       " ['horror', '60', 'Los Angeles Times', 'Mark Olsen'],\n",
       " ['horror', '50', 'Slant Magazine', 'Chuck Bowen'],\n",
       " ['horror', '40', 'The New York Times', 'Jeannette Catsoulis'],\n",
       " ['horror', '30', 'The Hollywood Reporter', 'Frank Scheck'],\n",
       " ['horror', '12', 'RogerEbert.com', 'Peter Sobczynski'],\n",
       " ['999', '91', 'Entertainment Weekly', 'Lisa Schwarzbaum'],\n",
       " ['999', '91', 'Christian Science Monitor', 'Peter Rainer'],\n",
       " ['999', '88', 'Philadelphia Inquirer', 'Steven Rea'],\n",
       " ['999', '75', 'The A.V. Club', 'Tasha Robinson'],\n",
       " ['999', '75', 'New York Post', 'Kyle Smith'],\n",
       " ['999', '75', 'Boston Globe', 'Janice Page'],\n",
       " ['999', '75', 'San Francisco Chronicle', 'Peter Hartlaub'],\n",
       " ['999', '75', 'St. Louis Post-Dispatch', 'Calvin Wilson'],\n",
       " ['999', '70', 'L.A. Weekly', 'Ella Taylor'],\n",
       " ['999', '70', 'The Hollywood Reporter', 'Kirk Honeycutt'],\n",
       " ['999', '70', 'The New York Times', 'A.O. Scott'],\n",
       " ['999', '70', 'Washington Post', \"Michael O'Sullivan\"],\n",
       " ['999', '50', 'Los Angeles Times', 'Sheri Linden'],\n",
       " ['999', '50', 'Variety', 'Eddie Cockrell'],\n",
       " ['999', '40', 'New York Daily News', 'Joe Neumaier'],\n",
       " ['pent', '70', 'Film.com', 'Ernest Hardy'],\n",
       " ['pent', '60', 'Los Angeles Times', 'Kevin Thomas'],\n",
       " ['pent', '60', 'Variety', 'David Sprague'],\n",
       " ['pent', '40', 'TV Guide Magazine', 'Maitland McDonagh'],\n",
       " ['pent', '30', 'Village Voice', 'Mark Holcomb'],\n",
       " ['pent', '30', 'The New York Times', 'A.O. Scott'],\n",
       " ['pent', '30', 'L.A. Weekly', 'Paul Malcolm'],\n",
       " ['pent', '25', 'New York Post', 'Jonathan Foreman']]"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Movies' from '../src/Movies.py'>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(Movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andy Wachowski', 'Lana Wachowski']"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ha.director"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'horror'"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_list[0][7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 2)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
